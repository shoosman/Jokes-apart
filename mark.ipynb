{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5df78103",
   "metadata": {},
   "source": [
    "Мы будем использовать алгоритм PageRank (разреженная цепь Маркова с телепортацией, α=0.85), чтобы для каждого трёхсловного паттерна (subj_pred_obj):\n",
    "\n",
    "Найти стационарную вероятность π — насколько часто паттерн «встречается» в устоявшейся модели.\n",
    "\n",
    "Посчитать энтропийную скорость H — среднее число бит неопределённости при переходе от одного паттерна к следующему."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a12260e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Entropy rate (jokes):      0.130890 bit/step\n",
      "Entropy rate (literature): 0.084958 bit/step\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "\n",
    "def build_graph_from_sequences(seqs):\n",
    "    G = nx.DiGraph()\n",
    "    for seq in seqs:\n",
    "        for u, v in zip(seq, seq[1:]):\n",
    "            if G.has_edge(u, v):\n",
    "                G[u][v]['weight'] += 1\n",
    "            else:\n",
    "                G.add_edge(u, v, weight=1)\n",
    "    return G\n",
    "\n",
    "def pagerank_and_entropy(G, alpha=0.85):\n",
    "    # 1) Считаем PageRank\n",
    "    pr = nx.pagerank(G, alpha=alpha, weight='weight', tol=1e-6)\n",
    "    pi_series = pd.Series(pr, name='pi').sort_values(ascending=False)\n",
    "\n",
    "    # 2) Считаем entropy rate\n",
    "    H = 0.0\n",
    "    for i in G.nodes():\n",
    "        pi_i = pr.get(i, 0.0)\n",
    "        nbrs = G[i]  # это dict: {j: attr_dict, ...}\n",
    "        total = sum(attr['weight'] for attr in nbrs.values())\n",
    "        if total == 0:\n",
    "            continue\n",
    "        for j, attr in nbrs.items():\n",
    "            p_ij = attr['weight'] / total\n",
    "            H -= pi_i * p_ij * np.log2(p_ij)\n",
    "    return pi_series, H\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # 1) Загрузка и подготовка, как у вас\n",
    "    jokes_df = (pd.read_csv('output_files/jokes_relations_clean.csv')\n",
    "                  .dropna(subset=['subj','pred','obj']))\n",
    "    lit_df   = (pd.read_csv('output_files/lit_relations_lit_clean.csv')\n",
    "                  .dropna(subset=['subj','pred','obj']))\n",
    "\n",
    "    jokes_df['order'] = jokes_df.groupby('joke_id').cumcount()\n",
    "    lit_df['order']   = lit_df.groupby('segment_id').cumcount()\n",
    "\n",
    "    joke_seqs = (\n",
    "        jokes_df\n",
    "          .sort_values(['joke_id','order'])\n",
    "          .groupby('joke_id')[['subj','pred','obj']]\n",
    "          .apply(lambda g: (g['subj'] + '_' + g['pred'] + '_' + g['obj']).tolist())\n",
    "          .tolist()\n",
    "    )\n",
    "    lit_seqs = (\n",
    "        lit_df\n",
    "          .sort_values(['segment_id','order'])\n",
    "          .groupby('segment_id')[['subj','pred','obj']]\n",
    "          .apply(lambda g: (g['subj'] + '_' + g['pred'] + '_' + g['obj']).tolist())\n",
    "          .tolist()\n",
    "    )\n",
    "\n",
    "    # 2) Строим графы\n",
    "    G_joke = build_graph_from_sequences(joke_seqs)\n",
    "    G_lit  = build_graph_from_sequences(lit_seqs)\n",
    "\n",
    "    # 3) Запускаем PageRank + считаем энтропию\n",
    "    pi_joke, H_joke = pagerank_and_entropy(G_joke, alpha=0.85)\n",
    "    pi_lit,  H_lit  = pagerank_and_entropy(G_lit,  alpha=0.85)\n",
    "\n",
    "    # 4) Сохраняем и выводим\n",
    "    pi_joke.to_csv('mark/pi_joke_stationary.csv', encoding='utf-8')\n",
    "    pi_lit.to_csv( 'mark/pi_lit_stationary.csv',  encoding='utf-8')\n",
    "    with open('entropy_rates.txt','w',encoding='utf-8') as f:\n",
    "        f.write(f\"Entropy rate (jokes):      {H_joke:.6f} bit/step\\n\")\n",
    "        f.write(f\"Entropy rate (literature): {H_lit:.6f} bit/step\\n\")\n",
    "\n",
    "    print(f\"Entropy rate (jokes):      {H_joke:.6f} bit/step\")\n",
    "    print(f\"Entropy rate (literature): {H_lit:.6f} bit/step\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30c7637c",
   "metadata": {},
   "source": [
    "**Энтропийная скорость H**\n",
    "\n",
    "- **Большое H** (например, ~0.13 в шутках) означает, что переходы между паттернами менее предсказуемы и более разнообразны.  \n",
    "- **Малое H** (например, ~0.085 в литературе) отражает более упорядоченные, повторяющиеся сочетания.  \n",
    "\n",
    "**Шутки**  \n",
    "Высокая энтропия говорит о том, что шутки часто «прыгают» между разными паттернами: неожиданные комбинации делают текст смешным. Такое свойство можно использовать как признак для автоматического выявления шуток среди обычного текста.\n",
    "\n",
    "**Литературные тексты**  \n",
    "Низкая энтропия характеризует более стройный, последовательный стиль: авторы придерживаются устойчивых фразовых оборотов. Это помогает отличать прозу или поэзию от юмористических жанров."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "51efc81f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top-20 паттернов в шутках (π_joke):\n",
      "звонок_в_дверь          0.000303\n",
      "раз_в_день              0.000226\n",
      "раз_в_год               0.000180\n",
      "раз_в_неделя            0.000176\n",
      "раз_в_жизнь             0.000161\n",
      "стук_в_дверь            0.000147\n",
      "сборная_по_футбол       0.000132\n",
      "ответ_на_вопрос         0.000126\n",
      "раз_в_месяц             0.000122\n",
      "чемпионат_по_футбол     0.000118\n",
      "жена_говорить_муж       0.000116\n",
      "вовочка_тянуть_рука     0.000105\n",
      "муж_говорить_жена       0.000104\n",
      "голос_из_зал            0.000102\n",
      "объявление_в_газета     0.000085\n",
      "борьба_с_коррупция      0.000074\n",
      "тест_на_беременность    0.000067\n",
      "цена_на_бензин          0.000064\n",
      "жена_открывать_дверь    0.000059\n",
      "фингал_под_глаз         0.000059\n",
      "Name: pi, dtype: float64\n",
      "\n",
      "Top-20 паттернов в литературе (π_lit):\n",
      "раз_в_жизнь            0.000109\n",
      "утро_до_вечер          0.000108\n",
      "день_и_ночь            0.000095\n",
      "рука_и_нога            0.000084\n",
      "раз_в_день             0.000074\n",
      "рубль_в_месяц          0.000068\n",
      "ответ_на_вопрос        0.000062\n",
      "отец_и_мать            0.000061\n",
      "утро_до_ночь           0.000055\n",
      "раз_в_год              0.000052\n",
      "мысль_прийти_голова    0.000051\n",
      "раз_в_неделя           0.000046\n",
      "жена_и_ребёнок         0.000044\n",
      "слеза_на_глаз          0.000044\n",
      "человек_с_лицо         0.000036\n",
      "лицо_и_глаз            0.000036\n",
      "жизнь_и_смерть         0.000036\n",
      "мужчина_и_женщина      0.000035\n",
      "волос_на_голова        0.000034\n",
      "любовь_к_человек       0.000034\n",
      "Name: pi, dtype: float64\n"
     ]
    }
   ],
   "source": [
    "# … после вызова pagerank_and_entropy …\n",
    "\n",
    "# Выводим топ-20 самых «центральных» паттернов\n",
    "print(\"Top-20 паттернов в шутках (π_joke):\")\n",
    "print(pi_joke.head(20))\n",
    "\n",
    "print(\"\\nTop-20 паттернов в литературе (π_lit):\")\n",
    "print(pi_lit.head(20))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_diploma",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
